# ğŸ©º HC4AI â€“ Explainability Module (Grad-CAM & Shapley)

This repository contains the **explainability part** of the HC4AI project,  
developed for the course *Human-Computer Interaction for Artificial Intelligence* (A.Y. 2022/2023, [Politecnico di Milano](https://www.polimi.it/)).

The complete project, including the conversational agent, can be found in the [colleagueâ€™s repo](https://github.com/rtjk/hci4ai-project).  
Here we focus on the **training and interpretation** of the CNN model for pneumonia detection.

---

## ğŸ“– Overview

The project implements a convolutional neural network (CNN) for pneumonia detection on chest X-ray images,  
with a focus on **interpretability**:

- **Grad-CAM** â†’ generates heatmaps showing the areas of the image most relevant for the modelâ€™s decision.  
- **Shapley values** â†’ highlights pixel contributions (positive/negative) to improve model transparency.  

This approach aims to provide medical students with an interpretable tool to understand and learn from the model predictions.

---

## ğŸ—‚ Repository Structure

```
ğŸ“ data/                # Sample chest X-ray images
ğŸ“ data_preparation/    # Pre-training of the CNN model
ğŸ“ notebook/            # Scripts for Grad-CAM (hc4ai_gradcam.ipynb) and Shapley (hc4ai_shapley.ipynb)
ğŸ“ output/              # Generated outputs (heatmaps, Shapley plots)
ğŸ“ src/                 # Source code (.py)
ğŸ“ results/             # Final report (PDF) and demo video
ğŸ“„ environment.yml      # .yaml to show conda environment spec
ğŸ“„ README.md
```

---

## ğŸ“Š Scripts

- `hc4ai_gradcam.py` â†’ Implementation of **Grad-CAM** to visualize pretrained CNN attention. 
- `hc4ai_gradcam_xception.py` â†’ Implementation of **Grad-CAM** to visualize Xception (from Keras) attention.  
- `hc4ai_shapley.py` â†’ Use of **SHAP** library to compute Shapley values for local explanations.  

Outputs are automatically saved under `output/`.

---

## ğŸ“‘ Results

- ğŸ“„ **HC4AI.pdf** â†’ Final project report.  
- ğŸ¥ **demo.mp4** â†’ Short demo showcasing explainability results.  
- ğŸ–¼ï¸ Grad-CAM and Shapley plots available in the `output/` folder.

---

## âš ï¸ Notes
 
- The CNN model is pre-trained and saved in `data_preparation/model_output/`.  
- Due to size limitations, full datasets are not included.  

---

## ğŸ‘¥ Authors

- Marco Gianvecchio  
- Giacomo Da Re  
- Lorenzo Manoni
